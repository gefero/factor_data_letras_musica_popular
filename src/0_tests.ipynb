{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_file = '../data/' + 'letras_total_ft.csv'\n",
    "train_file = '../data/' + 'letras_train.csv'\n",
    "test_file = '../data/' + '/letras_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/tango_rock.csv')\n",
    "data['texto'] = data['titulo'] + ' ' + data['letra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = data[['texto','genero']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do some cleaning of this text\n",
    "def clean_it(text,normalize=True):\n",
    "    # Replacing possible issues with data. We can add or reduce the replacemtent in this chain\n",
    "    s = str(text).replace(',',' ').replace('\"','').replace('\\'','').replace('.',' . ').replace('(',' ( ').\\\n",
    "            replace(')',' ) ').replace('!',' ! ').replace('?',' ? ').replace(':',' ').replace(';',' ').\\\n",
    "            replace('/','').replace('|','').replace('¿',' ¿ ').replace('¡',' ¡ ').lower()\n",
    "    \n",
    "    # normalizing / encoding the text\n",
    "    if normalize:\n",
    "        s = s.normalize('NFKD').str.encode('ascii','ignore').str.decode('utf-8')\n",
    "    \n",
    "    return s\n",
    "\n",
    "# Now lets define a small function where we can use above cleaning on datasets\n",
    "def clean_df(data, cleanit= False, shuffleit=False, encodeit=False, label_prefix='__label__'):\n",
    "    # Defining the new data\n",
    "    df = data[['texto']].copy(deep=True)\n",
    "    df['genero'] = label_prefix + data['genero'].astype(str) + ' '\n",
    "    \n",
    "    # cleaning it\n",
    "    if cleanit:\n",
    "        #df['name'] = df['name'].apply(lambda x: clean_it(x,encodeit))\n",
    "        df['texto'] = df['texto'].apply(lambda x: clean_it(x,encodeit))\n",
    "    \n",
    "    # shuffling it\n",
    "    if shuffleit:\n",
    "        df.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_indexes(X=ft_cleaned['texto'],\n",
    "                           y=ft_cleaned['genero'],\n",
    "                           size = 0.33,\n",
    "                           random_state=777,\n",
    "                         strat=ft_cleaned['genero']):\n",
    "    lista = train_test_split(X, y, test_size=size,\n",
    "                                       random_state=random_state, stratify=strat)\n",
    "    \n",
    "    train_index = lista[0].index\n",
    "    test_index = lista[1].index\n",
    "    \n",
    "    #return(pd.Series(train_index == lista[2].index))\n",
    "    #return(pd.Series(test_index == lista[3].index))\n",
    "    \n",
    "    return(train_index.values, test_index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft = ft_cleaned.iloc[get_train_test_indexes()[0],:]\n",
    "test_ft = ft_cleaned.iloc[get_train_test_indexes()[1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write files to disk as fastText classifier API reads files from disk.\n",
    "train_ft.to_csv(train_file, header=None, index=False, columns=['genero', 'texto'])\n",
    "\n",
    "test_ft.to_csv(test_file, header=None, index=False, columns=['genero', 'texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasttext import  train_unsupervised, train_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using fastText for feature extraction and training\n",
    "\"\"\"fastText expects and training file (csv), a model name as input arguments.\n",
    "label_prefix refers to the prefix before label string in the dataset.\n",
    "default is __label__. In our dataset, it is __class__. \n",
    "There are several other parameters which can be seen in: \n",
    "https://pypi.org/project/fasttext/\n",
    "\"\"\"\n",
    "model = train_unsupervised(\n",
    "                        input=total_file,\n",
    "                        #autotuneValidationFile=test_file,\n",
    "                        maxn=4,\n",
    "                        minn=2,\n",
    "                        lr=0.025, epoch=300, wordNgrams=1, \n",
    "                        dim=300, thread=16, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = {\"sentidos\" : [\"sentido\", \"sensación\", \"sentir\", \"suave\", \"duro\", \"frío\", \"caliente\", \n",
    "            \"oler\", \"asqueroso\", \"gusto\", \"dulce\", \"amargo\", \"oír\",\n",
    "            \"sonar\", \"silencio\", \"fuerte\", \"ver\", \"mirar\", \"vislumbrar\", \n",
    "            \"ligero\", \"oscuro\", \"brillante\"],\n",
    "\"creencia\" : [\"espíritu\", \"imaginar\", \"sabiduría\", \"sabio\", \"corazonada\", \n",
    "            \"mente\", \"sospecha\", \"creer\", \"pensar\", \"confiar\", \"fe\",\n",
    "            \"verdad\", \"creencia\", \"duda\", \"esperanza\", \"miedo\", \"vida\", \n",
    "            \"alma\", \"cielo\", \"eterno\", \"mortal\", \"santo\", \"dios\", \"orar\",\n",
    "            \"sobrenatural\", \"misterio\", \"sabio\"],\n",
    "\"cuerpo\" : [\"cabeza\", \"nariz\", \"boca\", \"oreja\", \"cabello\", \"hombro\", \"pecho\", \n",
    "          \"vientre\", \"pierna\", \"mano\", \"brazo\", \"dedo\"],\n",
    "\"pronombres\" : [\"yo\", \"nosotros\", \"tú\", \"él\", \"ella\", \"ellos\", \"mío\", \n",
    "               \"tu\", \"nuestro\", \"suyo\"],\n",
    "\"actividades\" : [\"caminar\", \"dormir\", \"gritar\", \"sentarse\", \"reír\", \"comer\", \"beber\", \"sonreír\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'yo': [(0.6709863543510437, 'que'),\n",
       "   (0.6623286604881287, 'me'),\n",
       "   (0.6494157910346985, 'pero'),\n",
       "   (0.6473472714424133, 'y'),\n",
       "   (0.6452637910842896, 'no'),\n",
       "   (0.6270315051078796, 'mi'),\n",
       "   (0.6248949766159058, 'te'),\n",
       "   (0.6119467616081238, 'soy'),\n",
       "   (0.594132661819458, 'lo'),\n",
       "   (0.5923551917076111, 'hoyyo')]},\n",
       " {'nosotros': [(0.9373599886894226, ',nosotros'),\n",
       "   (0.8846564292907715, '“nosotros'),\n",
       "   (0.7834941148757935, 'vosotros'),\n",
       "   (0.47439202666282654, 'potros'),\n",
       "   (0.470106840133667, 'lejísimo'),\n",
       "   (0.41293758153915405, 'wait`s'),\n",
       "   (0.4056229293346405, 'otros'),\n",
       "   (0.4041799008846283, 'aramos'),\n",
       "   (0.38781091570854187, 'nos'),\n",
       "   (0.3806556165218353, 'robamos')]},\n",
       " {'tú': [(0.5542171001434326, 'túeso'),\n",
       "   (0.4421008825302124, 'oyelé'),\n",
       "   (0.40519675612449646, 'ámalo'),\n",
       "   (0.4003676772117615, 'pídeme'),\n",
       "   (0.38878604769706726, 'heaven'),\n",
       "   (0.38592860102653503, 'túyo'),\n",
       "   (0.38236942887306213, 'electrográfico'),\n",
       "   (0.3804987967014313, 'gurú'),\n",
       "   (0.37749096751213074, 'túque'),\n",
       "   (0.37653908133506775, 'lewinsky')]},\n",
       " {'él': [(0.4374401569366455, 'él…'),\n",
       "   (0.3917306959629059, 'obispo'),\n",
       "   (0.3850512206554413, 'fermín'),\n",
       "   (0.36934083700180054, 'creído'),\n",
       "   (0.36161619424819946, 'alúmbrame'),\n",
       "   (0.35506531596183777, 'acrecentando'),\n",
       "   (0.3505236506462097, 'déjese'),\n",
       "   (0.34926876425743103, 'adivinó'),\n",
       "   (0.3482975959777832, 'cargó'),\n",
       "   (0.3451244533061981, 'sentó')]},\n",
       " {'ella': [(0.6975803375244141, ',ella'),\n",
       "   (0.5148110389709473, 'bella'),\n",
       "   (0.48917320370674133, 'mella'),\n",
       "   (0.4729744791984558, 'graziella'),\n",
       "   (0.4559233486652374, ',aquella'),\n",
       "   (0.45417866110801697, 'querella'),\n",
       "   (0.4480908215045929, 'su'),\n",
       "   (0.4431314170360565, 'devolvémela'),\n",
       "   (0.4396938681602478, ',estrella'),\n",
       "   (0.42808797955513, 'aquella')]},\n",
       " {'ellos': [(0.5626468658447266, 'sellos'),\n",
       "   (0.5453464984893799, 'bellos'),\n",
       "   (0.5285977721214294, 'camellos'),\n",
       "   (0.5196435451507568, 'cuellos'),\n",
       "   (0.5162704586982727, 'ello'),\n",
       "   (0.5022064447402954, 'destellos'),\n",
       "   (0.4736855924129486, 'aquellos'),\n",
       "   (0.47332292795181274, ',aquellos'),\n",
       "   (0.43470144271850586, 'rollos'),\n",
       "   (0.4329162538051605, 'pollos')]},\n",
       " {'mío': [(0.44240158796310425, 'míos'),\n",
       "   (0.4130120575428009, 'vacío'),\n",
       "   (0.40996211767196655, 'mahatma'),\n",
       "   (0.4089069366455078, 'estío'),\n",
       "   (0.39959362149238586, 'amordentro'),\n",
       "   (0.39497148990631104, '—tuyo'),\n",
       "   (0.38547325134277344, 'tuyo'),\n",
       "   (0.38003262877464294, 'hitler'),\n",
       "   (0.3793050944805145, 'exaltar'),\n",
       "   (0.37546053528785706, 'supuse')]},\n",
       " {'tu': [(0.754584014415741, 'mi'),\n",
       "   (0.6563079357147217, 'y'),\n",
       "   (0.6368584632873535, 'de'),\n",
       "   (0.6150700449943542, 'en'),\n",
       "   (0.601203203201294, 'que'),\n",
       "   (0.5724267959594727, 'la'),\n",
       "   (0.5647146701812744, 'el'),\n",
       "   (0.5615074634552002, 'con'),\n",
       "   (0.5610656142234802, 'tus'),\n",
       "   (0.5578485131263733, 'te')]},\n",
       " {'nuestro': [(0.8096449375152588, ',nuestro'),\n",
       "   (0.6526250839233398, 'vuestro'),\n",
       "   (0.6017513871192932, 'nuestros'),\n",
       "   (0.5185009837150574, 'nuestra'),\n",
       "   (0.48943856358528137, 'muestro'),\n",
       "   (0.48121941089630127, ',nuestra'),\n",
       "   (0.4738120138645172, 'nuestras'),\n",
       "   (0.4426249861717224, 'diestro'),\n",
       "   (0.42956504225730896, 'marcamos'),\n",
       "   (0.4241761863231659, 'secuestro')]},\n",
       " {'suyo': [(0.6762889623641968, 'suyos'),\n",
       "   (0.5224811434745789, 'yuyo'),\n",
       "   (0.4931303858757019, 'suya'),\n",
       "   (0.4776958227157593, '—tuyo'),\n",
       "   (0.4571775794029236, 'cuyo'),\n",
       "   (0.4150174558162689, 'maldecir'),\n",
       "   (0.4100896716117859, 'suyas'),\n",
       "   (0.40850770473480225, 'huyo'),\n",
       "   (0.4014371931552887, 'tuyo'),\n",
       "   (0.372546523809433, 'sueiro')]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{x:model.get_nearest_neighbors(x)} for x in key_words[\"pronombres\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_nearest_neighbors('ella', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
